# ğŸ›¡ï¸ Multi-Agent-Research-Lab

**Agentic-RAG-OS: Self-Correcting Research Pipeline**

Este proyecto implementa un sistema **multi-agente capaz de realizar investigaciÃ³n tÃ©cnica profunda de forma autÃ³noma**, utilizando exclusivamente **LLMs Open Source** y una **arquitectura de grafo cÃ­clico con auto-correcciÃ³n**.

---

# ğŸ¯ MotivaciÃ³n del Proyecto

Los pipelines **RAG tradicionales** suelen fallar ante:

- consultas complejas  
- informaciÃ³n contradictoria  
- falta de verificaciÃ³n de fuentes  

Este sistema resuelve el problema mediante un flujo **Plan â†’ Execute â†’ Verify**, donde un **agente crÃ­tico** valida la veracidad de las respuestas antes de darlas por finalizadas.

Esto reduce las **alucinaciones en aproximadamente un ~30%** (estimado mediante evaluaciones en Langfuse).

---

# ğŸ—ï¸ Arquitectura del Sistema

## Componentes Clave

**OrquestaciÃ³n**
- LangGraph para gestionar el estado y la lÃ³gica de re-intento (loops)

**Inferencia Local**
- IntegraciÃ³n con Hugging Face mediante **vLLM / Ollama**
- Modelos utilizados:
  - Llama-3.1-8B
  - Mistral-Nemo

**Memoria & Estado**
- Uso de **TypedDict** para mantener:
  - el hilo de investigaciÃ³n
  - las fuentes recuperadas

**Observabilidad**
- **Langfuse** para:
  - tracing completo
  - gestiÃ³n de prompts
  - evaluaciÃ³n de fidelidad (Faithfulness)

---

# ğŸ› ï¸ Stack TecnolÃ³gico

| Capa | Herramienta | RazÃ³n de elecciÃ³n |
|-----|-------------|-------------------|
| Agentes | LangGraph | Soporta ciclos y persistencia de estado mejor que LangChain puro |
| Modelos (LLM) | Llama-3.1-8B | Buen equilibrio entre latencia y seguimiento de instrucciones en local |
| Embeddings | sentence-transformers/all-MiniLM-L6-v2 | Alta eficiencia en CPU/GPU |
| Database | ChromaDB / Qdrant | Vector store ligero y open-source |
| Monitoring | Langfuse | Tracing de pasos intermedios y debugging de agent thoughts |

---

# ğŸš€ LÃ³gica de Auto-CorrecciÃ³n (The Router)

El nÃºcleo del proyecto es la capacidad del sistema para **decidir si una investigaciÃ³n es suficiente**.

Implementamos una **arista condicional** basada en la evaluaciÃ³n del nodo **Reviewer**.

```python
def route_after_review(state: AgentState):
    # LÃ³gica de decisiÃ³n tÃ©cnica
    
    if state["revisions_count"] >= 3:
        return "finalizer"  # salida de seguridad por lÃ­mite de intentos
    
    if "FAIL" in state["critique"]:
        return "researcher" # reintento de bÃºsqueda con feedback
    
    return "finalizer"      # aprobado
```

Este sistema permite:

- reintentar investigaciones incompletas  
- evitar loops infinitos  
- garantizar una respuesta validada

---

# ğŸ“ˆ Observabilidad y EvaluaciÃ³n

A diferencia de otros proyectos, este incluye una suite de evaluaciÃ³n **LLM-as-a-Judge**.

### CaracterÃ­sticas

**Traceability**
- Cada ejecuciÃ³n genera un **ID Ãºnico en Langfuse**

**Dataset Testing**
- Dataset interno de **20 preguntas complejas**
- Permite medir el **Success Rate** del pipeline de revisiÃ³n

---

# ğŸ› ï¸ InstalaciÃ³n y Uso Local

```bash
# Clonar repositorio
git clone https://github.com/tu-usuario/agentic-rag-os.git

# Instalar dependencias (Python 3.10+ recomendado)
pip install -r requirements.txt

# Levantar servicios (Langfuse + VectorDB)
docker-compose up -d

# Ejecutar el agente
python main.py --query "Explica las vulnerabilidades de reentrada en Solidity"
```

---

# ğŸ§  Lecciones Aprendidas

**CuantizaciÃ³n**
- El uso de modelos en **4-bit** puede afectar la capacidad de razonamiento del agente planificador.

**Control de Bucles**
- Es crucial mantener **contadores de estado** para evitar loops infinitos en grafos cÃ­clicos.

**Prompt Engineering**
- Existen diferencias importantes entre prompts diseÃ±ados para:
  - modelos OpenAI
  - modelos open-source como Llama-3 en local

---

# ğŸ“Œ Futuras Mejoras

- IntegraciÃ³n con **rerankers neuronales**
- Mejor sistema de evaluaciÃ³n automÃ¡tica
- Soporte para **multi-document reasoning**
- UI para visualizaciÃ³n del grafo de agentes

---

# ğŸ“œ Licencia

MIT License